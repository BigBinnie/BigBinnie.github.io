<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Binwei Yao</title>
    <link>https://github.io/project/</link>
      <atom:link href="https://github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 09 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://github.io/project/</link>
    </image>
    
    <item>
      <title>MobileNet</title>
      <link>https://github.io/project/1-mobilenet/</link>
      <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://github.io/project/1-mobilenet/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1801.04381.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MobileNet&lt;/a&gt; is a class of efficient light weight deep networks for mobile and embedded vision applications, which have fewer parameters and a relatively lower amount of calculation. Mobilenets use depthwise separable convolutions, which could be divided into depthwise and pointwise convolutions.&lt;/p&gt;
&lt;p&gt;Since most of the model&amp;rsquo;s operations are convolutions, our project focuses on optimizing the related operations of convolutions. Our optimizing method includes: improving the parallelism by assigning the calculation task of each pixel to a thread, avoiding unnecessary memory data handling, and putting operations such as memory application in the model initialization stage as much as possible.&lt;/p&gt;
&lt;p&gt;With above optimizations, we went from 2s per inference initially to only 7.7ms per inference.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hierarchical Chatbot</title>
      <link>https://github.io/project/2-chatbot/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://github.io/project/2-chatbot/</guid>
      <description>&lt;p&gt;The chatbot has a hierarchical framework comprising the utterance encoder, the context encoder, and the decoder. RNN, as the utterance encoder, encodes the words in an utterance. The transformer encoder, as the context encoder, encodes the utterance encoder&amp;rsquo;s output, and the RNN decoder takes the attention calculation result of the context encoder as the input.&lt;/p&gt;
&lt;p&gt;The strength of such a model is that the utterance encoder makes it possible for us to input a more extended context of the dialogue for restriction by the Transformer&amp;rsquo;s input size. Considering the Transformer we used isn&amp;rsquo;t pretrained in advance, the model performance is limited.&lt;/p&gt;
&lt;p&gt;The model implemented by us is 0.03 higher than the baseline on F1_BLEU.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SRCNN</title>
      <link>https://github.io/project/3-srcnn/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://github.io/project/3-srcnn/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1501.00092.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SRCNN&lt;/a&gt; learns an end-to-end
mapping between the low/high-resolution images by convolutional neural network (CNN). Given a low-resolution image Y, the first convolutional layer of the SRCNN extracts a set of feature maps. The second layer maps these feature maps nonlinearly to high-resolution patch representations. The last layer combines the predictions within a spatial neighbourhood to produce the final high-resolution image.&lt;/p&gt;
&lt;p&gt;This learning project aims at reproducing the SRCNN.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Naive Gdocs</title>
      <link>https://github.io/project/4-gdocs/</link>
      <pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate>
      <guid>https://github.io/project/4-gdocs/</guid>
      <description>&lt;p&gt;Naive Gdocs is a shared document platform supporting collaborative editing like &lt;a href=&#34;https://www.google.com/docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Docs&lt;/a&gt;, based on a distributed system. This project includes the frontend by React, backend by Springboot, distributed file system by &lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zookeeper&lt;/a&gt;, Redis lock server, and MongoDB database.&lt;/p&gt;
&lt;p&gt;For the front end, WebSocket is used to synchronize editing status. For the backend, Redis, as memory storage, is used as a lock server to assure correct execution of operations. The distributed file system comprises Master, ChunkServer, Client node, and Zookeeper cluster. The Master is mainly responsible for maintaining the metadata of the file system, the ChunkServer is accountable for the storage of file data in the file system, the Client is responsible for providing the file system interface to the upper-layer application, and the Zookeeper is responsible for coordinating each member in the system which maintains the read-write locks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Amoy Interest</title>
      <link>https://github.io/project/5-amoy/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://github.io/project/5-amoy/</guid>
      <description>&lt;p&gt;Amoy Interest, meaning finding your interest in Chinese, is a social media platform like &lt;a href=&#34;https://twitter.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twitter&lt;/a&gt; and &lt;a href=&#34;https://weibo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Weibo&lt;/a&gt;. Users could share their daily life with everyone on the platform and make friends with people having the same interests conveniently.&lt;/p&gt;
&lt;p&gt;The frontend of this platform is built by React, and the Backend is built by SpringBoot. We store data by Mycat for master-slave storage to increase the read-write speed. Additionally, we construct our CI-CD environment by Jenkins.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>KV Store</title>
      <link>https://github.io/project/6-kvstore/</link>
      <pubDate>Wed, 08 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://github.io/project/6-kvstore/</guid>
      <description>&lt;p&gt;The KV storage system is based on a log-­structured merge-­tree in the disk and skiplist cache in memory. The MemTable in memory caches small-scale data in memory for quick read-write operations, and the SSTable have a level structure which stores data by a log-structured merge-tree.&lt;/p&gt;
&lt;p&gt;By optimizing the way of adding, deleting, checking, and modifying using algorithms like MergeSort, I constructed a quick KV Store system.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
